from typing import Any

from jupyterlab_chat.models import Message
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory

from ...history import YChatHistory
from ..base_persona import BasePersona, PersonaDefaults
from .prompt_template import JUPYTERNAUT_PROMPT_TEMPLATE, JupyternautVariables


class JupyternautPersona(BasePersona):
    """
    The Jupyternaut persona, the main persona provided by Jupyter AI.
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    @property
    def defaults(self):
        return PersonaDefaults(
            name="Jupyternaut",
            avatar_path="/api/ai/static/jupyternaut.svg",
            description="The standard agent provided by JupyterLab. Currently has no tools.",
            system_prompt="...",
        )

    async def process_message(self, message: Message) -> None:
        print(f"[DEBUG] process_message called, message: {message}")
        print(f"[DEBUG] config_manager.lm_provider: {self.config_manager.lm_provider}")
        print(f"[DEBUG] config_manager.lm_provider_params: {self.config_manager.lm_provider_params}")
        if not self.config_manager.lm_provider:
            self.send_message(
                "No language model provider configured. Please set one in the Jupyter AI settings."
            )
            return

        provider_name = self.config_manager.lm_provider.name
        model_id = self.config_manager.lm_provider_params["model_id"]

        # Process file attachments and include their content in the context
        context = self.process_attachments(message)
        print(f"[DEBUG] context from attachments: {context}")

        runnable = self.build_runnable()
        print(f"[DEBUG] runnable object: {runnable}")
        variables = JupyternautVariables(
            input=message.body,
            model_id=model_id,
            provider_name=provider_name,
            persona_name=self.name,
            context=context,
        )
        print(f"[DEBUG] JupyternautVariables: {variables}")
        variables_dict = variables.model_dump()
        print(f"[DEBUG] variables_dict: {variables_dict}")
        reply_stream = runnable.astream(variables_dict)
        print(f"[DEBUG] reply_stream created: {reply_stream}")
        await self.stream_message(reply_stream)

    def build_runnable(self) -> Any:
        print(f"[DEBUG] build_runnable called")
        print(f"[DEBUG] lm_provider: {self.config_manager.lm_provider}")
        print(f"[DEBUG] lm_provider_params: {self.config_manager.lm_provider_params}")
        llm = self.config_manager.lm_provider(**self.config_manager.lm_provider_params)
        print(f"[DEBUG] llm object: {llm}")
        print(f"[DEBUG] JUPYTERNAUT_PROMPT_TEMPLATE: {JUPYTERNAUT_PROMPT_TEMPLATE}")
        runnable = JUPYTERNAUT_PROMPT_TEMPLATE | llm | StrOutputParser()
        print(f"[DEBUG] runnable pipeline: {runnable}")

        runnable = RunnableWithMessageHistory(
            runnable=runnable,  #  type:ignore[arg-type]
            get_session_history=lambda: YChatHistory(ychat=self.ychat, k=2),
            input_messages_key="input",
            history_messages_key="history",
        )
        print(f"[DEBUG] RunnableWithMessageHistory: {runnable}")

        return runnable
