# from typing import Any

# from jupyterlab_chat.models import Message
# from langchain_core.output_parsers import StrOutputParser
# from langchain_core.runnables.history import RunnableWithMessageHistory

# from ...history import YChatHistory
# from ..base_persona import BasePersona, PersonaDefaults
# from .prompt_template import JUPYTERNAUT_PROMPT_TEMPLATE, JupyternautVariables
# import os
# from ..company_ai.rag_system import RAGSystem
# class JupyternautPersona(BasePersona):
#     """
#     The Jupyternaut persona, the main persona provided by Jupyter AI.
#     """
    
#     print("ðŸ”§ DEBUG: JupyternautPersona ç±»è¢«åŠ è½½")

#     def __init__(self, *args, **kwargs):
#         print("ðŸš€ DEBUG: JupyternautPersona.__init__ è¢«è°ƒç”¨")
#         print(f"ðŸ”§ DEBUG: å‚æ•°: args={args}, kwargs={kwargs}")
#         super().__init__(*args, **kwargs)
#         print("âœ… DEBUG: JupyternautPersona.__init__ å®Œæˆ")

#     @property
#     def defaults(self):
#         return PersonaDefaults(
#             name="Jupyternaut",
#             avatar_path="/api/ai/static/jupyternaut.svg",
#             description="The standard agent provided by JupyterLab. Currently has no tools.",
#             system_prompt="...",
#         )
#     import os
#     def _initialize_rag_system(self):
#         try:
#             self._rag_system = RAGSystem()
#             print("[DEBUG] RAGSystem åˆå§‹åŒ–æˆåŠŸ")
#         except Exception as e:
#             print(f"[DEBUG] RAGSystem åˆå§‹åŒ–å¤±è´¥: {e}")
#             self._rag_system = None

#     def get_rag_context(self, query: str) -> str:
#         if not hasattr(self, '_rag_system') or self._rag_system is None:
#             self._initialize_rag_system()
#         if not self._rag_system:
#             return f"RAGç³»ç»Ÿä¸å¯ç”¨ï¼Œæ— æ³•æ£€ç´¢ '{query}' çš„ç›¸å…³å†…å®¹ã€‚"
#         try:
#             search_results = self._rag_system.search(query, top_k=5)
#             if not search_results:
#                 return f"æœªæ‰¾åˆ° '{query}' çš„ç›¸å…³æ–‡æ¡£ä¿¡æ¯ã€‚"
#             context_parts = ["## ç›¸å…³æ–‡æ¡£ä¿¡æ¯\n"]
#             for i, result in enumerate(search_results, 1):
#                 context_parts.append(f"### {i}. {result.get('title', 'æ— æ ‡é¢˜')}")
#                 context_parts.append(f"**ç›¸ä¼¼åº¦**: {result.get('similarity_score', 0):.3f}")
#                 context_parts.append(f"**å†…å®¹**:\n{result.get('content', '')}\n")
#             return "\n".join(context_parts)
#         except Exception as e:
#             print(f"[DEBUG] RAG æ£€ç´¢å¼‚å¸¸: {e}")
#             return f"RAGæ£€ç´¢å¼‚å¸¸: {e}"

#     async def process_message(self, message: Message) -> None:
#         print("=" * 80)
#         print("ðŸš€ðŸš€ðŸš€ JUPYTERNAUT PROCESS_MESSAGE å¼€å§‹æ‰§è¡Œ ðŸš€ðŸš€ðŸš€")
#         print("=" * 80)
#         print("ðŸš€ DEBUG: process_message å¼€å§‹æ‰§è¡Œ")
#         print(f"ðŸ” DEBUG: æ”¶åˆ°æ¶ˆæ¯: {message.body}")
        
#         # å…ˆå‘é€ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯ç¡®è®¤ä»£ç æ‰§è¡Œ
#         self.send_message("ðŸ”§ è°ƒè¯•ï¼šJupyternautPersona.process_message æ­£åœ¨æ‰§è¡Œ...")
        
#         if not self.config_manager.lm_provider:
#             print("âŒ DEBUG: æ²¡æœ‰é…ç½®è¯­è¨€æ¨¡åž‹æä¾›è€…")
#             self.send_message(
#                 "No language model provider configured. Please set one in the Jupyter AI settings."
#             )
#             return

#         provider_name = self.config_manager.lm_provider.name
#         model_id = self.config_manager.lm_provider_params["model_id"]
#         print(f"ðŸ”§ DEBUG: ä½¿ç”¨æä¾›è€…: {provider_name}, æ¨¡åž‹: {model_id}")
#         print(f"ðŸ”§ DEBUG: æä¾›è€…å‚æ•°: {self.config_manager.lm_provider_params}")
        
#         # å‘é€é…ç½®ä¿¡æ¯ç¡®è®¤
#         self.send_message(f"ðŸ”§ é…ç½®ç¡®è®¤ï¼šæä¾›è€…={provider_name}, æ¨¡åž‹={model_id}")



#         rag_context = self.get_rag_context(message.body)
#        # print(f"[DEBUG] RAG æ£€ç´¢ç»“æžœ: {rag_context}")

#         # Process file attachments and include their content in the context
#         attach_context = self.process_attachments(message)
#         print(f"ðŸ“Ž DEBUG: é™„ä»¶å¤„ç†åŽçš„ä¸Šä¸‹æ–‡é•¿åº¦: {len(attach_context) if attach_context else 0}")

#         # åˆå¹¶ RAG æ£€ç´¢å’Œé™„ä»¶å†…å®¹
#         if attach_context:
#             context = rag_context + "\n" + attach_context
#         else:
#             context = rag_context
#         print(f"[DEBUG] æœ€ç»ˆ context: {context}")

#         print("ðŸ”¨ DEBUG: å¼€å§‹æž„å»º runnable...")
#         try:
#             runnable = self.build_runnable()
#             print(f"âœ… DEBUG: runnable æž„å»ºå®Œæˆï¼Œç±»åž‹: {type(runnable)}")
#             self.send_message("ðŸ”§ runnable æž„å»ºæˆåŠŸ")
#         except Exception as e:
#             print(f"âŒ DEBUG: runnable æž„å»ºå¤±è´¥: {e}")
#             self.send_message(f"âŒ runnable æž„å»ºå¤±è´¥: {e}")
#             return
        
#         variables = JupyternautVariables(
#             input=message.body,
#             model_id=model_id,
#             provider_name=provider_name,
#             persona_name=self.name,
#             context=context,
#         )
#         variables_dict = variables.model_dump()
#         print(f"ðŸ“ DEBUG: å˜é‡å‡†å¤‡å®Œæˆ: {variables_dict}")
#         reply_stream=runnable.astream(variables_dict)
#         await self.stream_message(reply_stream)


#     def build_runnable(self) -> Any:
#         print("ðŸ”¨ DEBUG: build_runnable å¼€å§‹æ‰§è¡Œ")
        
#         # TODO: support model parameters. maybe we just add it to lm_provider_params in both 2.x and 3.x
#         print("ðŸ”§ DEBUG: åˆ›å»ºè¯­è¨€æ¨¡åž‹å®žä¾‹...")
#         try:
#             llm = self.config_manager.lm_provider(**self.config_manager.lm_provider_params)
#             print(f"âœ… DEBUG: è¯­è¨€æ¨¡åž‹åˆ›å»ºæˆåŠŸï¼Œç±»åž‹: {type(llm)}")
#             print(f"ðŸ”§ DEBUG: LLM å®žä¾‹: {llm}")
#         except Exception as e:
#             print(f"âŒ DEBUG: è¯­è¨€æ¨¡åž‹åˆ›å»ºå¤±è´¥: {e}")
#             import traceback
#             print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             raise
        
#         print("ðŸ”§ DEBUG: æž„å»ºåŸºç¡€é“¾...")
#         try:
#             # ç®€åŒ–é“¾æž„å»ºï¼Œå…ˆæµ‹è¯•åŸºæœ¬åŠŸèƒ½
#             runnable = JUPYTERNAUT_PROMPT_TEMPLATE | llm | StrOutputParser()
#             print(f"âœ… DEBUG: åŸºç¡€é“¾æž„å»ºæˆåŠŸï¼Œç±»åž‹: {type(runnable)}")
#             print(f"ðŸ”§ DEBUG: åŸºç¡€é“¾: {runnable}")
#         except Exception as e:
#             print(f"âŒ DEBUG: åŸºç¡€é“¾æž„å»ºå¤±è´¥: {e}")
#             import traceback
#             print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             raise

#         print("ðŸ”§ DEBUG: æ·»åŠ æ¶ˆæ¯åŽ†å²æ”¯æŒ...")
#         try:
#             runnable = RunnableWithMessageHistory(
#                 runnable=runnable,  #  type:ignore[arg-type]
#                 get_session_history=lambda: YChatHistory(ychat=self.ychat, k=2),
#                 input_messages_key="input",
#                 history_messages_key="history",
#             )
#             print(f"âœ… DEBUG: æ¶ˆæ¯åŽ†å²æ”¯æŒæ·»åŠ æˆåŠŸï¼Œç±»åž‹: {type(runnable)}")
#         except Exception as e:
#             print(f"âŒ DEBUG: æ¶ˆæ¯åŽ†å²æ”¯æŒæ·»åŠ å¤±è´¥: {e}")
#             import traceback
#             print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             raise

#         print("âœ… DEBUG: build_runnable å®Œæˆ")
#         return runnable
from typing import Any

from jupyterlab_chat.models import Message
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory

from ...history import YChatHistory
from ..base_persona import BasePersona, PersonaDefaults
from .prompt_template import JUPYTERNAUT_PROMPT_TEMPLATE, JupyternautVariables
import os
from ..company_ai.rag_system import RAGSystem

# class JupyternautPersona(BasePersona):
#     """
#     The Jupyternaut persona, the main persona provided by Jupyter AI.
#     """
    
#     print("ðŸ”§ DEBUG: JupyternautPersona ç±»è¢«åŠ è½½")

#     def __init__(self, *args, **kwargs):
#         print("ðŸš€ DEBUG: JupyternautPersona.__init__ è¢«è°ƒç”¨")
#         print(f"ðŸ”§ DEBUG: å‚æ•°: args={args}, kwargs={kwargs}")
#         super().__init__(*args, **kwargs)
#         print("âœ… DEBUG: JupyternautPersona.__init__ å®Œæˆ")

#     @property
#     def defaults(self):
#         return PersonaDefaults(
#             name="Jupyternaut",
#             avatar_path="/api/ai/static/jupyternaut.svg",
#             description="The standard agent provided by JupyterLab. Currently has no tools.",
#             system_prompt="...",
#         )

#     def _initialize_rag_system(self):
#         print("ðŸ”§ DEBUG: _initialize_rag_system å¼€å§‹æ‰§è¡Œ")
#         try:
#             self._rag_system = RAGSystem()
#             print("[DEBUG] RAGSystem åˆå§‹åŒ–æˆåŠŸ")
#         except Exception as e:
#             print(f"[DEBUG] RAGSystem åˆå§‹åŒ–å¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"[DEBUG] RAGSystem åˆå§‹åŒ–é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             self._rag_system = None

#     def get_rag_context(self, query: str) -> str:
#         print(f"ðŸ” DEBUG: get_rag_context å¼€å§‹æ‰§è¡Œï¼ŒæŸ¥è¯¢: {query}")
#         if not hasattr(self, '_rag_system') or self._rag_system is None:
#             print("[DEBUG] RAGSystem æœªåˆå§‹åŒ–ï¼Œå°è¯•åˆå§‹åŒ–")
#             self._initialize_rag_system()
#         if not self._rag_system:
#             print("[DEBUG] RAGSystem ä¸å¯ç”¨")
#             return f"RAGç³»ç»Ÿä¸å¯ç”¨ï¼Œæ— æ³•æ£€ç´¢ '{query}' çš„ç›¸å…³å†…å®¹ã€‚"
#         try:
#             print("[DEBUG] å¼€å§‹ RAG æ£€ç´¢...")
#             search_results = self._rag_system.search(query, top_k=3)
#             print(f"[DEBUG] RAG æ£€ç´¢ç»“æžœæ•°é‡: {len(search_results) if search_results else 0}")
#             if not search_results:
#                 print(f"[DEBUG] æœªæ‰¾åˆ° '{query}' çš„ç›¸å…³æ–‡æ¡£")
#                 return f"æœªæ‰¾åˆ° '{query}' çš„ç›¸å…³æ–‡æ¡£ä¿¡æ¯ã€‚"
#             context_parts = ["## ç›¸å…³æ–‡æ¡£ä¿¡æ¯\n"]
#             for i, result in enumerate(search_results, 1):
#                 print(f"[DEBUG] å¤„ç† RAG ç»“æžœ {i}: æ ‡é¢˜={result.get('title', 'æ— æ ‡é¢˜')}, ç›¸ä¼¼åº¦={result.get('similarity_score', 0):.3f}")
#                 context_parts.append(f"### {i}. {result.get('title', 'æ— æ ‡é¢˜')}")
#                 context_parts.append(f"**ç›¸ä¼¼åº¦**: {result.get('similarity_score', 0):.3f}")
#                 context_parts.append(f"**å†…å®¹**:\n{result.get('content', '')}\n")
#             context = "\n".join(context_parts)
#             print(f"[DEBUG] RAG ä¸Šä¸‹æ–‡ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(context)} å­—ç¬¦")
#             return context
#         except Exception as e:
#             print(f"[DEBUG] RAG æ£€ç´¢å¼‚å¸¸: {type(e).__name__} - {e}")
#             import traceback
#             print(f"[DEBUG] RAG æ£€ç´¢é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             return f"RAGæ£€ç´¢å¼‚å¸¸: {e}"

#     async def process_message(self, message: Message) -> None:
#         print("=" * 80)
#         print("ðŸš€ðŸš€ðŸš€ JUPYTERNAUT PROCESS_MESSAGE å¼€å§‹æ‰§è¡Œ ðŸš€ðŸš€ðŸš€")
#         print("=" * 80)
#         print("ðŸš€ DEBUG: process_message å¼€å§‹æ‰§è¡Œ")
#         print(f"ðŸ” DEBUG: æ”¶åˆ°æ¶ˆæ¯: {message.body}")
#         print(f"ðŸ” DEBUG: æ¶ˆæ¯å¯¹è±¡: {repr(message)}")
        
#         # å…ˆå‘é€ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯ç¡®è®¤ä»£ç æ‰§è¡Œ
#         self.send_message("ðŸ”§ è°ƒè¯•ï¼šJupyternautPersona.process_message æ­£åœ¨æ‰§è¡Œ...")
        
#         if not self.config_manager.lm_provider:
#             print("âŒ DEBUG: æ²¡æœ‰é…ç½®è¯­è¨€æ¨¡åž‹æä¾›è€…")
#             self.send_message(
#                 "No language model provider configured. Please set one in the Jupyter AI settings."
#             )
#             return

#         provider_name = self.config_manager.lm_provider.name
#         model_id = self.config_manager.lm_provider_params["model_id"]
#         print(f"ðŸ”§ DEBUG: ä½¿ç”¨æä¾›è€…: {provider_name}, æ¨¡åž‹: {model_id}")
#         print(f"ðŸ”§ DEBUG: æä¾›è€…å‚æ•°: {self.config_manager.lm_provider_params}")
        
#         # å‘é€é…ç½®ä¿¡æ¯ç¡®è®¤
#         self.send_message(f"ðŸ”§ é…ç½®ç¡®è®¤ï¼šæä¾›è€…={provider_name}, æ¨¡åž‹={model_id}")

#         print("ðŸ” DEBUG: å¼€å§‹èŽ·å– RAG ä¸Šä¸‹æ–‡")
#         rag_context = self.get_rag_context(message.body)
#         print(f"[DEBUG] RAG æ£€ç´¢ç»“æžœé•¿åº¦: {len(rag_context)} å­—ç¬¦")
#        # print(f"[DEBUG] RAG æ£€ç´¢ç»“æžœ (å‰500å­—ç¬¦): {rag_context[:500]}...")

#         # Process file attachments and include their content in the context
#         print("ðŸ“Ž DEBUG: å¼€å§‹å¤„ç†é™„ä»¶")
#         attach_context = self.process_attachments(message)
#         print(f"ðŸ“Ž DEBUG: é™„ä»¶å¤„ç†åŽçš„ä¸Šä¸‹æ–‡é•¿åº¦: {len(attach_context) if attach_context else 0}")
#         if attach_context:
#             print(f"ðŸ“Ž DEBUG: é™„ä»¶ä¸Šä¸‹æ–‡ (å‰500å­—ç¬¦): {attach_context[:500]}...")

#         # åˆå¹¶ RAG æ£€ç´¢å’Œé™„ä»¶å†…å®¹
#         if attach_context:
#             context = rag_context + "\n" + attach_context
#         else:
#             context = rag_context
#         print(f"[DEBUG] æœ€ç»ˆåˆå¹¶ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
#         print(f"[DEBUG] æœ€ç»ˆåˆå¹¶ä¸Šä¸‹æ–‡ (å‰500å­—ç¬¦): {context[:500]}...")

#         print("ðŸ”¨ DEBUG: å¼€å§‹æž„å»º runnable...")
#         try:
#             runnable = self.build_runnable()
#             print(f"âœ… DEBUG: runnable æž„å»ºå®Œæˆï¼Œç±»åž‹: {type(runnable)}")
#             self.send_message("ðŸ”§ runnable æž„å»ºæˆåŠŸ")
#         except Exception as e:
#             print(f"âŒ DEBUG: runnable æž„å»ºå¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"âŒ DEBUG: runnable æž„å»ºé”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             self.send_message(f"âŒ runnable æž„å»ºå¤±è´¥: {e}")
#             return
        
#         variables = JupyternautVariables(
#             input=message.body,
#             model_id=model_id,
#             provider_name=provider_name,
#             persona_name=self.name,
#             context=context,
#         )
#         variables_dict = variables.model_dump()
#         print(f"ðŸ“ DEBUG: å˜é‡å‡†å¤‡å®Œæˆ: {variables_dict}")
#         print(f"ðŸ“ DEBUG: å˜é‡å­—å…¸é”®: {list(variables_dict.keys())}")
#         print(f"ðŸ“ DEBUG: è¾“å…¥å†…å®¹é•¿åº¦: {len(variables_dict.get('input', ''))} å­—ç¬¦")
#         print(f"ðŸ“ DEBUG: ä¸Šä¸‹æ–‡å†…å®¹é•¿åº¦: {len(variables_dict.get('context', ''))} å­—ç¬¦")
#         print("ðŸ” DEBUG: æµ‹è¯•åŒæ­¥è°ƒç”¨ runnable.invoke...")
#         try:
#             sync_result = await runnable.invoke(variables_dict)
#             print(f"[DEBUG] åŒæ­¥è°ƒç”¨ç»“æžœ: {sync_result}")
#             self.send_message(f"ðŸ”§ åŒæ­¥è°ƒç”¨ç»“æžœ: {sync_result}")
#         except Exception as e:
#             print(f"[DEBUG] åŒæ­¥è°ƒç”¨å¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"[DEBUG] åŒæ­¥è°ƒç”¨é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             self.send_message(f"âŒ åŒæ­¥è°ƒç”¨å¤±è´¥: {e}")
#             return
#         print("ðŸ”„ DEBUG: å¼€å§‹åˆ›å»º reply_stream...")
#         try:
#             reply_stream = runnable.astream(variables_dict)
#             print(f"âœ… DEBUG: reply_stream åˆ›å»ºæˆåŠŸï¼Œç±»åž‹: {type(reply_stream)}")
#             print(f"ðŸ” DEBUG: reply_stream å¯¹è±¡: {repr(reply_stream)}")
#         except Exception as e:
#             print(f"âŒ DEBUG: reply_stream åˆ›å»ºå¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"âŒ DEBUG: reply_stream åˆ›å»ºé”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             self.send_message(f"âŒ reply_stream åˆ›å»ºå¤±è´¥: {e}")
#             return

#         # æ‰‹åŠ¨æµ‹è¯• reply_stream
#         print("ðŸ” DEBUG: æ‰‹åŠ¨æµ‹è¯• reply_stream...")
#         try:
#             agen = reply_stream.__aiter__()
#             for i in range(5):
#                 try:
#                     chunk = await agen.__anext__()
#                     print(f"[DEBUG] reply_stream æ‰‹åŠ¨äº§å‡º chunk[{i}]: {chunk}")
#                 except StopAsyncIteration:
#                     print(f"[DEBUG] reply_stream æ‰‹åŠ¨äº§å‡º StopAsyncIteration at {i}")
#                     break
#                 except Exception as e:
#                     print(f"[DEBUG] reply_stream æ‰‹åŠ¨äº§å‡ºå¼‚å¸¸: {type(e).__name__} - {e}")
#                     import traceback
#                     print(f"[DEBUG] reply_stream æ‰‹åŠ¨äº§å‡ºé”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#                     break
#         except Exception as e:
#             print(f"[DEBUG] reply_stream __aiter__() å¼‚å¸¸: {type(e).__name__} - {e}")
#             import traceback
#             print(f"[DEBUG] reply_stream __aiter__() é”™è¯¯å †æ ˆ: {traceback.format_exc()}")

#         print("ðŸ”„ DEBUG: å¼€å§‹æµå¼å¤„ç† reply_stream...")
#         await self.stream_message(reply_stream)

#     def build_runnable(self) -> Any:
#         print("ðŸ”¨ DEBUG: build_runnable å¼€å§‹æ‰§è¡Œ")
        
#         # TODO: support model parameters. maybe we just add it to lm_provider_params in both 2.x and 3.x
#         print("ðŸ”§ DEBUG: åˆ›å»ºè¯­è¨€æ¨¡åž‹å®žä¾‹...")
#         try:
            
#             llm = self.config_manager.lm_provider(**self.config_manager.lm_provider_params)
#             #llm = self.config_manager.lm_provider(**params)
#             print(f"å®žé™…è®¿é—®{self.config_manager.lm_provider_params}")
#             print(f"âœ… DEBUG: è¯­è¨€æ¨¡åž‹åˆ›å»ºæˆåŠŸï¼Œç±»åž‹: {type(llm)}")
#             print(f"ðŸ”§ DEBUG: LLM å®žä¾‹: {repr(llm)}")
#         except Exception as e:
#             print(f"âŒ DEBUG: è¯­è¨€æ¨¡åž‹åˆ›å»ºå¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             raise
        
#         print("ðŸ”§ DEBUG: æž„å»ºåŸºç¡€é“¾...")
#         try:
#             # ç®€åŒ–é“¾æž„å»ºï¼Œå…ˆæµ‹è¯•åŸºæœ¬åŠŸèƒ½
#             runnable = JUPYTERNAUT_PROMPT_TEMPLATE | llm | StrOutputParser()
#             print(f"âœ… DEBUG: åŸºç¡€é“¾æž„å»ºæˆåŠŸï¼Œç±»åž‹: {type(runnable)}")
#             print(f"ðŸ”§ DEBUG: åŸºç¡€é“¾: {repr(runnable)}")
#         except Exception as e:
#             print(f"âŒ DEBUG: åŸºç¡€é“¾æž„å»ºå¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             raise

#         print("ðŸ”§ DEBUG: æ·»åŠ æ¶ˆæ¯åŽ†å²æ”¯æŒ...")
#         try:
#             runnable = RunnableWithMessageHistory(
#                 runnable=runnable,  #  type:ignore[arg-type]
#                 get_session_history=lambda: YChatHistory(ychat=self.ychat, k=2),
#                 input_messages_key="input",
#                 history_messages_key="history",
#             )
#             print(f"âœ… DEBUG: æ¶ˆæ¯åŽ†å²æ”¯æŒæ·»åŠ æˆåŠŸï¼Œç±»åž‹: {type(runnable)}")
#             print(f"ðŸ”§ DEBUG: æœ€ç»ˆ runnable: {repr(runnable)}")
#         except Exception as e:
#             print(f"âŒ DEBUG: æ¶ˆæ¯åŽ†å²æ”¯æŒæ·»åŠ å¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             raise

#         print("âœ… DEBUG: build_runnable å®Œæˆ")
#         return runnable
from typing import Any, List, Iterator, Dict
from jupyterlab_chat.models import Message
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.runnables.base import RunnableLambda
from langchain_core.messages import BaseMessage
from ...history import YChatHistory
from ..base_persona import BasePersona, PersonaDefaults
from .prompt_template import JUPYTERNAUT_PROMPT_TEMPLATE, JupyternautVariables
import os
from ..company_ai.rag_system import RAGSystem
import requests
import json
import asyncio
from .env_config import get_model_config, get_embedding_config, validate_config

class CustomStrOutputParser(StrOutputParser):
    """è‡ªå®šä¹‰è§£æžå™¨ï¼Œå¤„ç†æµå¼ chunk"""
    def parse(self, output):
        print(f"[DEBUG] CustomStrOutputParser è§£æžè¾“å‡º: {output}")
        if isinstance(output, dict) and "choices" in output:
            choices = output.get("choices", [])
            if choices and "delta" in choices[0]:
                content = choices[0]["delta"].get("content", "")
                print(f"[DEBUG] æå– content: {content}")
                return content
            elif choices and "finish_reason" in choices[0]:
                print(f"[DEBUG] ç»“æŸåŽŸå› : {choices[0]['finish_reason']}")
                return ""
        return str(output) if output else ""

class JupyternautPersona(BasePersona):
    print("ðŸ”§ DEBUG: JupyternautPersona ç±»è¢«åŠ è½½")

    def __init__(self, *args, **kwargs):
        print("ðŸš€ DEBUG: JupyternautPersona.__init__ è¢«è°ƒç”¨")
        super().__init__(*args, **kwargs)
        print("âœ… DEBUG: JupyternautPersona.__init__ å®Œæˆ")

    @property
    def defaults(self):
        return PersonaDefaults(
            name="Jupyternaut",
            avatar_path="/api/ai/static/jupyternaut.svg",
            description="The standard agent provided by JupyterLab. Currently has no tools.",
            system_prompt="...",
        )

    def _initialize_rag_system(self):
        print("ðŸ”§ DEBUG: _initialize_rag_system å¼€å§‹æ‰§è¡Œ")
        try:
            self._rag_system = RAGSystem()
            print("[DEBUG] RAGSystem åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"[DEBUG] RAGSystem åˆå§‹åŒ–å¤±è´¥: {type(e).__name__} - {e}")
            import traceback
            print(f"[DEBUG] RAGSystem é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            self._rag_system = None

    def get_rag_context(self, query: str) -> str:
        print(f"ðŸ” DEBUG: get_rag_context æŸ¥è¯¢: {query}")
        if not hasattr(self, '_rag_system') or self._rag_system is None:
            self._initialize_rag_system()
        if not self._rag_system:
            print("[DEBUG] RAGSystem ä¸å¯ç”¨")
            return f"RAGç³»ç»Ÿä¸å¯ç”¨ï¼Œæ— æ³•æ£€ç´¢ '{query}' çš„ç›¸å…³å†…å®¹ã€‚"
        try:
            search_results = self._rag_system.search(query, top_k=3, max_content_length=500, max_segments=2)
            print(f"[DEBUG] RAG æ£€ç´¢ç»“æžœæ•°é‡: {len(search_results) if search_results else 0}")
            if not search_results:
                print(f"[DEBUG] æœªæ‰¾åˆ° '{query}' çš„ç›¸å…³æ–‡æ¡£")
                return f"æœªæ‰¾åˆ° '{query}' çš„ç›¸å…³æ–‡æ¡£ä¿¡æ¯ã€‚"
            context_parts = ["## ç›¸å…³æ–‡æ¡£ä¿¡æ¯\n"]
            for i, result in enumerate(search_results, 1):
                context_parts.append(f"### {i}. {result.get('title', 'æ— æ ‡é¢˜')}")
                context_parts.append(f"**ç›¸ä¼¼åº¦**: {result.get('similarity_score', 0):.3f}")
                context_parts.append(f"**å†…å®¹**:\n{result.get('content', '')}\n")
            context = "\n".join(context_parts)[:2000]
            print(f"[DEBUG] RAG ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
            return context
        except Exception as e:
            print(f"[DEBUG] RAG æ£€ç´¢å¼‚å¸¸: {type(e).__name__} - {e}")
            import traceback
            print(f"[DEBUG] RAG æ£€ç´¢é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return f"RAGæ£€ç´¢å¼‚å¸¸: {e}"

    def check_context_length(self, formatted_prompt: str, history: List[BaseMessage], api_base: str, api_key: str, model: str = None) -> dict:
        print("[DEBUG] check_context_length å¼€å§‹æ‰§è¡Œ")
        
        # Use environment variable default if model not provided
        if model is None:
            model_config = get_model_config()
            model = model_config["model_id"]
        
        max_tokens = 128000
        try:
            headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
            response = requests.get(f"{api_base}/models/{model}", headers=headers)
            if response.status_code == 200:
                model_info = response.json()
                max_tokens = model_info.get("max_tokens", 128000)
                print(f"[DEBUG] ä»Ž API èŽ·å–æ¨¡åž‹ {model} æœ€å¤§ token æ•°: {max_tokens}")
            else:
                print(f"[DEBUG] èŽ·å–æ¨¡åž‹ä¿¡æ¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œä½¿ç”¨é»˜è®¤ 128000")
        except Exception as e:
            print(f"[DEBUG] èŽ·å–æ¨¡åž‹ä¿¡æ¯å¼‚å¸¸: {type(e).__name__} - {e}")
            print("[DEBUG] ä½¿ç”¨é»˜è®¤æœ€å¤§ token æ•°: 128000")

        def estimate_tokens(text: str) -> int:
            return len(text) // 2.5
        prompt_tokens = estimate_tokens(formatted_prompt)
        history_tokens = sum(estimate_tokens(str(msg)) for msg in history)
        total_tokens = prompt_tokens + history_tokens
        
        print(f"[DEBUG] ä¼°ç®— token æ•°: prompt={prompt_tokens}, history={history_tokens}, total={total_tokens}")
        print(f"[DEBUG] æœ€å¤§å…è®¸ token æ•°: {max_tokens}")
        
        return {
            "max_tokens": max_tokens,
            "prompt_tokens": prompt_tokens,
            "history_tokens": history_tokens,
            "total_tokens": total_tokens,
            "is_exceeded": total_tokens > max_tokens
        }

    async def process_message(self, message: Message) -> None:
        print("ðŸš€ DEBUG: process_message å¼€å§‹æ‰§è¡Œ")
        print(f"ðŸ” DEBUG: æ”¶åˆ°æ¶ˆæ¯: {message.body}")
        
        self.send_message("ðŸ”§ è°ƒè¯•ï¼šJupyternautPersona.process_message æ­£åœ¨æ‰§è¡Œ...")
        
        if not self.config_manager.lm_provider:
            print("âŒ DEBUG: æ²¡æœ‰é…ç½®è¯­è¨€æ¨¡åž‹æä¾›è€…")
            self.send_message(
                "No language model provider configured. Please set one in the Jupyter AI settings."
            )
            return

        provider_name = self.config_manager.lm_provider.name
        model_id = self.config_manager.lm_provider_params["model_id"]
        
        # Get API configuration from environment variables with fallback to config
        model_config = get_model_config()
        api_base = self.config_manager.lm_provider_params.get("openai_api_base", model_config["api_base"])
        
        # ä¼˜å…ˆä½¿ç”¨çŽ¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥ï¼Œå¦‚æžœçŽ¯å¢ƒå˜é‡ä¸­æœ‰å€¼çš„è¯
        env_api_key = model_config["api_key"]
        config_api_key = self.config_manager.lm_provider_params.get("openai_api_key", "")
        
        if env_api_key and env_api_key != "":
            api_key = env_api_key
            print(f"ðŸ”§ DEBUG: ä½¿ç”¨çŽ¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
        elif config_api_key and config_api_key != "":
            api_key = config_api_key
            print(f"ðŸ”§ DEBUG: ä½¿ç”¨é…ç½®ç®¡ç†å™¨ä¸­çš„APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
        else:
            api_key = env_api_key  # ä½¿ç”¨çŽ¯å¢ƒå˜é‡é»˜è®¤å€¼
            print(f"ðŸ”§ DEBUG: ä½¿ç”¨é»˜è®¤APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
        
        print(f"ðŸ”§ DEBUG: æä¾›è€…: {provider_name}, æ¨¡åž‹: {model_id}, API ç«¯ç‚¹: {api_base}")
        
        self.send_message(f"ðŸ”§ é…ç½®ç¡®è®¤ï¼šæä¾›è€…={provider_name}, æ¨¡åž‹={model_id}")

        rag_context = self.get_rag_context(message.body)
        print(f"[DEBUG] RAG ä¸Šä¸‹æ–‡é•¿åº¦: {len(rag_context)} å­—ç¬¦")

        attach_context = self.process_attachments(message)
        print(f"ðŸ“Ž DEBUG: é™„ä»¶ä¸Šä¸‹æ–‡é•¿åº¦: {len(attach_context) if attach_context else 0}")

        context = rag_context + ("\n" + attach_context if attach_context else "")
        print(f"[DEBUG] æœ€ç»ˆä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")

        print("ðŸ”¨ DEBUG: å¼€å§‹æž„å»º runnable...")
        try:
            runnable = self.build_runnable()
            print(f"âœ… DEBUG: runnable æž„å»ºå®Œæˆï¼Œç±»åž‹: {type(runnable)}")
            self.send_message("ðŸ”§ runnable æž„å»ºæˆåŠŸ")
        except Exception as e:
            print(f"âŒ DEBUG: runnable æž„å»ºå¤±è´¥: {type(e).__name__} - {e}")
            import traceback
            print(f"âŒ DEBUG: runnable é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            self.send_message(f"âŒ runnable æž„å»ºå¤±è´¥: {e}")
            return
        
        variables = JupyternautVariables(
            input=message.body,
            model_id=model_id,
            provider_name=provider_name,
            persona_name=self.name,
            context=context,
            history=[]  # åˆå§‹åŒ–ä¸ºç©º
        )
        
        history = []
        try:
            session_history = YChatHistory(ychat=self.ychat, k=2).messages
            history = session_history if session_history else []
            print(f"[DEBUG] åŽ†å²æ¶ˆæ¯æ•°é‡: {len(history)}, å†…å®¹: {history}")
        except Exception as e:
            print(f"[DEBUG] èŽ·å–åŽ†å²æ¶ˆæ¯å¤±è´¥: {type(e).__name__} - {e}")

        variables_dict = variables.model_dump()
        variables_dict["history"] = history
        print(f"ðŸ“ DEBUG: å˜é‡å‡†å¤‡å®Œæˆï¼Œinputé•¿åº¦: {len(variables_dict.get('input', ''))}, contexté•¿åº¦: {len(variables_dict.get('context', ''))}, historyé•¿åº¦: {sum(len(str(msg)) for msg in history)}")

        print("ðŸ” DEBUG: æ ¼å¼åŒ– prompt...")
        try:
            formatted_prompt = JUPYTERNAUT_PROMPT_TEMPLATE.format(**variables_dict)
            print(f"[DEBUG] æ ¼å¼åŒ– prompt é•¿åº¦: {len(formatted_prompt)} å­—ç¬¦")
        except Exception as e:
            print(f"[DEBUG] æ ¼å¼åŒ– prompt å¤±è´¥: {type(e).__name__} - {e}")
            import traceback
            print(f"[DEBUG] æ ¼å¼åŒ– prompt é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            self.send_message(f"âŒ prompt æ ¼å¼åŒ–å¤±è´¥: {e}")
            return

        print("ðŸ” DEBUG: æ£€æŸ¥ä¸Šä¸‹æ–‡é•¿åº¦...")
        length_info = self.check_context_length(formatted_prompt, history, api_base, api_key, model_id)
        print(f"[DEBUG] ä¸Šä¸‹æ–‡é•¿åº¦æ£€æŸ¥ç»“æžœ: {length_info}")
        if length_info["is_exceeded"]:
            self.send_message(f"âŒ ä¸Šä¸‹æ–‡é•¿åº¦è¶…è¿‡é™åˆ¶: æ€»è®¡ {length_info['total_tokens']} tokensï¼Œæœ€å¤§å…è®¸ {length_info['max_tokens']} tokens")
            return

        # ä½¿ç”¨ LangChain æµå¼è¾“å‡ºï¼ˆæŒ‰å¥å­ç¼“å†²ï¼‰
        print("ðŸ”„ DEBUG: å¼€å§‹åˆ›å»º reply_stream...")
        try:
            reply_stream = runnable.astream(variables_dict)
            print(f"âœ… DEBUG: reply_stream åˆ›å»ºæˆåŠŸï¼Œç±»åž‹: {type(reply_stream)}")
            buffer = ""
            chunk_count = 0
            async for chunk in reply_stream:
                print(f"[DEBUG] LangChain chunk[{chunk_count}]: {chunk}")
                if chunk:
                    buffer += chunk
                    if any(buffer.endswith(p) for p in [".", "!", "?", "\n"]):
                        self.send_message(buffer.strip())
                        print(f"[DEBUG] å‘é€å¥å­: {buffer.strip()}")
                        buffer = ""
                    elif len(buffer) > 200:
                        self.send_message(buffer.strip())
                        print(f"[DEBUG] å‘é€é•¿ç¼“å†²: {buffer.strip()}")
                        buffer = ""
                chunk_count += 1
            if buffer:
                self.send_message(buffer.strip())
                print(f"[DEBUG] å‘é€å‰©ä½™ç¼“å†²: {buffer.strip()}")
            print(f"[DEBUG] LangChain æ€»è®¡æŽ¥æ”¶ {chunk_count} ä¸ª chunk")
            if chunk_count == 0:
                self.send_message("âŒ LangChain æœªæŽ¥æ”¶åˆ°ä»»ä½• chunkï¼Œå¯èƒ½æ˜¯è§£æžé—®é¢˜")
        except Exception as e:
            print(f"[DEBUG] reply_stream å¼‚å¸¸: {type(e).__name__} - {e}")
            import traceback
            print(f"[DEBUG] reply_stream é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            self.send_message(f"âŒ reply_stream å¼‚å¸¸: {e}")

        # è°ƒè¯•ï¼šç›´æŽ¥ API è°ƒç”¨ï¼ˆä»…ç”¨äºŽå¯¹æ¯”ï¼‰
        print("ðŸ” DEBUG: ç›´æŽ¥ä½¿ç”¨ API æµå¼è¾“å‡ºï¼ˆä»…ç”¨äºŽå¯¹æ¯”ï¼‰...")
        try:
            headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
            messages = [
                {"role": "system", "content": formatted_prompt},
                {"role": "user", "content": message.body}
            ]
            data = {
                "model": model_id,
                "messages": messages,
                "stream": True,
                "max_tokens": 4000,
                "temperature": 0.3
            }
            buffer = ""
            with requests.post(api_base, headers=headers, json=data, stream=True) as r:
                # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                if r.status_code != 200:
                    print(f"âŒ èŠå¤©APIè¯·æ±‚å¤±è´¥: {r.status_code} - {r.text}")
                    return
                
                chunk_count = 0
                for line in r.iter_lines():
                    if line:
                        decoded_line = line.decode("utf-8")
                        print(f"[DEBUG] API chunk[{chunk_count}]: {decoded_line}")
                        
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
                        if "code" in decoded_line and "401" in decoded_line:
                            print(f"âŒ èŠå¤©APIè®¤è¯å¤±è´¥: {decoded_line}")
                            return
                        
                        if decoded_line.startswith("data: ") and decoded_line != "data: [DONE]":
                            try:
                                chunk_data = json.loads(decoded_line[6:])
                                if "choices" in chunk_data and chunk_data["choices"]:
                                    content = chunk_data["choices"][0].get("delta", {}).get("content", "")
                                    if content:
                                        buffer += content
                                        if any(buffer.endswith(p) for p in [".", "!", "?", "\n"]):
                                            print(f"[DEBUG] API å‘é€å¥å­: {buffer.strip()}")
                                            buffer = ""
                                        elif len(buffer) > 200:
                                            print(f"[DEBUG] API å‘é€é•¿ç¼“å†²: {buffer.strip()}")
                                            buffer = ""
                                chunk_count += 1
                            except json.JSONDecodeError:
                                print(f"[DEBUG] JSON è§£æžå¤±è´¥: {decoded_line}")
                if buffer:
                    print(f"[DEBUG] API å‘é€å‰©ä½™ç¼“å†²: {buffer.strip()}")
                print(f"[DEBUG] API æ€»è®¡æŽ¥æ”¶ {chunk_count} ä¸ª chunk")
        except Exception as e:
            print(f"[DEBUG] ç›´æŽ¥ API æµå¼å¤„ç†å¤±è´¥: {type(e).__name__} - {e}")
            import traceback
            print(f"[DEBUG] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            self.send_message(f"âŒ API æµå¼å¤„ç†å¤±è´¥: {e}")

    def build_runnable(self) -> Any:
        print("ðŸ”¨ DEBUG: build_runnable å¼€å§‹æ‰§è¡Œ")
        
        print("ðŸ”§ DEBUG: åˆ›å»ºè¯­è¨€æ¨¡åž‹å®žä¾‹...")
        async def stream_llm(input: Any) -> Iterator[str]:
            print(f"[DEBUG] stream_llm è°ƒç”¨: input={str(input)[:50]}...")
            
            # Get API configuration from environment variables with fallback to config
            model_config = get_model_config()
            model_id = self.config_manager.lm_provider_params.get("model_id", model_config["model_id"])
            api_base = self.config_manager.lm_provider_params.get("openai_api_base", model_config["api_base"])
            
            # ä¼˜å…ˆä½¿ç”¨çŽ¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥ï¼Œå¦‚æžœçŽ¯å¢ƒå˜é‡ä¸­æœ‰å€¼çš„è¯
            env_api_key = model_config["api_key"]
            config_api_key = self.config_manager.lm_provider_params.get("openai_api_key", "")
            
            if env_api_key and env_api_key != "":
                api_key = env_api_key
                print(f"ðŸ”§ DEBUG: stream_llm ä½¿ç”¨çŽ¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
            elif config_api_key and config_api_key != "":
                api_key = config_api_key
                print(f"ðŸ”§ DEBUG: stream_llm ä½¿ç”¨é…ç½®ç®¡ç†å™¨ä¸­çš„APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
            else:
                api_key = env_api_key  # ä½¿ç”¨çŽ¯å¢ƒå˜é‡é»˜è®¤å€¼
                print(f"ðŸ”§ DEBUG: stream_llm ä½¿ç”¨é»˜è®¤APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
            prompt = str(input)  # å°†è¾“å…¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            try:
                headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
                data = {
                    "model": model_id,
                    "messages": [{"role": "user", "content": prompt}],
                    "stream": True,
                    "max_tokens": 4000,
                    "temperature": 0.3
                }
                print(f"[DEBUG] å‘é€ API è¯·æ±‚åˆ°: {api_base}")
                print(f"[DEBUG] è¯·æ±‚å¤´: {headers}")
                print(f"[DEBUG] è¯·æ±‚æ•°æ®: {json.dumps(data, ensure_ascii=False)[:100]}...")
                with requests.post(
                    api_base,
                    headers=headers,
                    json=data,
                    stream=True
                ) as response:
                    # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                    if response.status_code != 200:
                        print(f"âŒ èŠå¤©APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                        return
                    
                    chunk_count = 0
                    buffer = ""
                    in_code_block = False
                    for line in response.iter_lines():
                        if line:
                            decoded_line = line.decode("utf-8")
                            print(f"[DEBUG] Raw chunk[{chunk_count}]: {decoded_line}")
                            
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
                            if "code" in decoded_line and "401" in decoded_line:
                                print(f"âŒ èŠå¤©APIè®¤è¯å¤±è´¥: {decoded_line}")
                                return
                            
                            if decoded_line.startswith("data: ") and decoded_line != "data: [DONE]":
                                try:
                                    chunk_data = json.loads(decoded_line[6:])
                                    print(f"[DEBUG] Parsed chunk[{chunk_count}]: {chunk_data}")
                                    if "choices" in chunk_data and chunk_data["choices"]:
                                        content = chunk_data["choices"][0].get("delta", {}).get("content", "")
                                        if content:
                                            buffer += content
                                            
                                            # æ£€æŸ¥ä»£ç å—å¼€å§‹
                                            if "```" in buffer and not in_code_block:
                                                parts = buffer.split("```", 1)
                                                if len(parts) == 2:
                                                    yield parts[0] + "```"
                                                    buffer = parts[1]
                                                    in_code_block = True
                                                else:
                                                    # åªæœ‰å¼€å§‹æ ‡è®°ï¼Œç»§ç»­ç¼“å†²
                                                    pass
                                            # æ£€æŸ¥ä»£ç å—ç»“æŸ
                                            elif "```" in buffer and in_code_block:
                                                parts = buffer.split("```", 1)
                                                if len(parts) == 2:
                                                    yield parts[0] + "```"
                                                    buffer = parts[1]
                                                    in_code_block = False
                                                else:
                                                    # åªæœ‰ç»“æŸæ ‡è®°ï¼Œç»§ç»­ç¼“å†²
                                                    pass
                                            # å¦‚æžœä¸åœ¨ä»£ç å—ä¸­ä¸”æ²¡æœ‰ç‰¹æ®Šæ ‡è®°ï¼Œç›´æŽ¥è¾“å‡º
                                            elif not in_code_block and not "```" in buffer:
                                                yield content
                                                buffer = ""
                                        elif chunk_data["choices"][0].get("finish_reason"):
                                            yield ""
                                    else:
                                        print(f"[DEBUG] è·³è¿‡éžç”Ÿæˆ chunk: {chunk_data}")
                                    chunk_count += 1
                                except json.JSONDecodeError:
                                    print(f"[DEBUG] JSON è§£æžå¤±è´¥: {decoded_line}")
                    
                    # å¤„ç†å‰©ä½™çš„ç¼“å†²å†…å®¹
                    if buffer:
                        yield buffer
                    
                    print(f"[DEBUG] stream_llm æ€»è®¡æŽ¥æ”¶ {chunk_count} ä¸ª chunk")
            except Exception as e:
                print(f"[DEBUG] stream_llm å¼‚å¸¸: {type(e).__name__} - {e}")
                import traceback
                print(f"[DEBUG] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                raise

        try:
            llm = RunnableLambda(stream_llm)
            print(f"âœ… DEBUG: è¯­è¨€æ¨¡åž‹åˆ›å»ºæˆåŠŸï¼Œç±»åž‹: {type(llm)}")
        except Exception as e:
            print(f"âŒ DEBUG: è¯­è¨€æ¨¡åž‹åˆ›å»ºå¤±è´¥: {type(e).__name__} - {e}")
            import traceback
            print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
        
        print("ðŸ”§ DEBUG: æž„å»ºåŸºç¡€é“¾...")
        try:
            runnable = JUPYTERNAUT_PROMPT_TEMPLATE | llm | CustomStrOutputParser()
            print(f"âœ… DEBUG: åŸºç¡€é“¾æž„å»ºæˆåŠŸï¼Œç±»åž‹: {type(runnable)}")
        except Exception as e:
            print(f"âŒ DEBUG: åŸºç¡€é“¾æž„å»ºå¤±è´¥: {type(e).__name__} - {e}")
            import traceback
            print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise

        print("ðŸ”§ DEBUG: æ·»åŠ æ¶ˆæ¯åŽ†å²æ”¯æŒ...")
        try:
            history_obj = YChatHistory(ychat=self.ychat, k=2)
            try:
                history_messages = history_obj.messages
                print(f"[DEBUG] åŽ†å²æ¶ˆæ¯: {history_messages}")
            except Exception as e:
                print(f"[DEBUG] èŽ·å– YChatHistory æ¶ˆæ¯å¤±è´¥: {type(e).__name__} - {e}")
            
            runnable = RunnableWithMessageHistory(
                runnable=runnable,
                get_session_history=lambda: history_obj,
                input_messages_key="input",
                history_messages_key="history",
            )
            print(f"âœ… DEBUG: æ¶ˆæ¯åŽ†å²æ”¯æŒæ·»åŠ æˆåŠŸï¼Œç±»åž‹: {type(runnable)}")
        except Exception as e:
            print(f"âŒ DEBUG: æ¶ˆæ¯åŽ†å²æ”¯æŒæ·»åŠ å¤±è´¥: {type(e).__name__} - {e}")
            import traceback
            print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise

        print("âœ… DEBUG: build_runnable å®Œæˆ")
        return runnable
# from typing import Any, List, Iterator, Dict
# from jupyterlab_chat.models import Message
# from langchain_core.output_parsers import StrOutputParser
# from langchain_core.runnables.history import RunnableWithMessageHistory
# from langchain_core.runnables.base import RunnableLambda
# from langchain_core.messages import BaseMessage
# from ...history import YChatHistory
# from ..base_persona import BasePersona, PersonaDefaults
# from .prompt_template import JUPYTERNAUT_PROMPT_TEMPLATE, JupyternautVariables
# import os
# import requests
# import json
# import asyncio
# import re
# from ..company_ai.rag_system import RAGSystem
# class CustomStrOutputParser(StrOutputParser):
#     """è‡ªå®šä¹‰è§£æžå™¨ï¼Œå¤„ç†æµå¼ chunk"""
#     def parse(self, output):
#         print(f"[DEBUG] CustomStrOutputParser è§£æžè¾“å‡º: {output}")
#         if isinstance(output, dict) and "choices" in output:
#             choices = output.get("choices", [])
#             if choices and "delta" in choices[0]:
#                 content = choices[0]["delta"].get("content", "")
#                 print(f"[DEBUG] æå– content: {content}")
#                 return content
#             elif choices and "finish_reason" in choices[0]:
#                 print(f"[DEBUG] ç»“æŸåŽŸå› : {choices[0]['finish_reason']}")
#                 return ""
#         return str(output) if output else ""

# class JupyternautPersona(BasePersona):
#     print("ðŸ”§ DEBUG: JupyternautPersona ç±»è¢«åŠ è½½")

#     def __init__(self, *args, **kwargs):
#         print("ðŸš€ DEBUG: JupyternautPersona.__init__ è¢«è°ƒç”¨")
#         super().__init__(*args, **kwargs)
#         print("âœ… DEBUG: JupyternautPersona.__init__ å®Œæˆ")

#     @property
#     def defaults(self):
#         return PersonaDefaults(
#             name="Jupyternaut",
#             avatar_path="/api/ai/static/jupyternaut.svg",
#             description="The standard agent provided by JupyterLab. Currently has no tools.",
#             system_prompt="...",
#         )

#     def _initialize_rag_system(self):
#         print("ðŸ”§ DEBUG: _initialize_rag_system å¼€å§‹æ‰§è¡Œ")
#         try:
#             self._rag_system = RAGSystem()
#             print("[DEBUG] RAGSystem åˆå§‹åŒ–æˆåŠŸ")
#         except Exception as e:
#             print(f"[DEBUG] RAGSystem åˆå§‹åŒ–å¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"[DEBUG] RAGSystem é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             self._rag_system = None

#     def get_rag_context(self, query: str) -> str:
#         print(f"ðŸ” DEBUG: get_rag_context æŸ¥è¯¢: {query}")
#         if not hasattr(self, '_rag_system') or self._rag_system is None:
#             self._initialize_rag_system()
#         if not self._rag_system:
#             print("[DEBUG] RAGSystem ä¸å¯ç”¨")
#             return f"RAGç³»ç»Ÿä¸å¯ç”¨ï¼Œæ— æ³•æ£€ç´¢ '{query}' çš„ç›¸å…³å†…å®¹ã€‚"
#         try:
#             search_results = self._rag_system.search(query, top_k=3, max_content_length=500, max_segments=2)
#             print(f"[DEBUG] RAG æ£€ç´¢ç»“æžœæ•°é‡: {len(search_results) if search_results else 0}")
#             if not search_results:
#                 print(f"[DEBUG] æœªæ‰¾åˆ° '{query}' çš„ç›¸å…³æ–‡æ¡£")
#                 return f"æœªæ‰¾åˆ° '{query}' çš„ç›¸å…³æ–‡æ¡£ä¿¡æ¯ã€‚"
#             context_parts = ["## ç›¸å…³æ–‡æ¡£ä¿¡æ¯\n"]
#             for i, result in enumerate(search_results, 1):
#                 context_parts.append(f"### {i}. {result.get('title', 'æ— æ ‡é¢˜')}")
#                 context_parts.append(f"**ç›¸ä¼¼åº¦**: {result.get('similarity_score', 0):.3f}")
#                 context_parts.append(f"**å†…å®¹**:\n{result.get('content', '')}\n")
#             context = "\n".join(context_parts)[:2000]
#             print(f"[DEBUG] RAG ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
#             return context
#         except Exception as e:
#             print(f"[DEBUG] RAG æ£€ç´¢å¼‚å¸¸: {type(e).__name__} - {e}")
#             import traceback
#             print(f"[DEBUG] RAG æ£€ç´¢é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             return f"RAGæ£€ç´¢å¼‚å¸¸: {e}"

#     def check_context_length(self, formatted_prompt: str, history: List[BaseMessage], api_base: str, api_key: str, model: str = "gpt-4o") -> dict:
#         print("[DEBUG] check_context_length å¼€å§‹æ‰§è¡Œ")
        
#         max_tokens = 128000
#         try:
#             headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
#             response = requests.get(f"{api_base}/models/{model}", headers=headers)
#             if response.status_code == 200:
#                 model_info = response.json()
#                 max_tokens = model_info.get("max_tokens", 128000)
#                 print(f"[DEBUG] ä»Ž API èŽ·å–æ¨¡åž‹ {model} æœ€å¤§ token æ•°: {max_tokens}")
#             else:
#                 print(f"[DEBUG] èŽ·å–æ¨¡åž‹ä¿¡æ¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œä½¿ç”¨é»˜è®¤ 128000")
#         except Exception as e:
#             print(f"[DEBUG] èŽ·å–æ¨¡åž‹ä¿¡æ¯å¼‚å¸¸: {type(e).__name__} - {e}")
#             print("[DEBUG] ä½¿ç”¨é»˜è®¤æœ€å¤§ token æ•°: 128000")

#         def estimate_tokens(text: str) -> int:
#             return len(text) // 2.5
#         prompt_tokens = estimate_tokens(formatted_prompt)
#         history_tokens = sum(estimate_tokens(str(msg)) for msg in history)
#         total_tokens = prompt_tokens + history_tokens
        
#         print(f"[DEBUG] ä¼°ç®— token æ•°: prompt={prompt_tokens}, history={history_tokens}, total={total_tokens}")
#         print(f"[DEBUG] æœ€å¤§å…è®¸ token æ•°: {max_tokens}")
        
#         return {
#             "max_tokens": max_tokens,
#             "prompt_tokens": prompt_tokens,
#             "history_tokens": history_tokens,
#             "total_tokens": total_tokens,
#             "is_exceeded": total_tokens > max_tokens
#         }

#     def is_code_content(self, content: str) -> bool:
#         """Detect if content appears to be code (e.g., Python syntax)."""
#         code_patterns = [
#             r'^\s*def\s+\w+\s*\(',  # Function definition
#             r'^\s*import\s+\w+',     # Import statement
#             r'^\s*class\s+\w+',      # Class definition
#             r'^\s*[\w\s=]+:\s*$',    # Dictionary or type hints
#             r'^\s{2,}',              # Indented code
#             r'print\(',              # Common Python function
#         ]
#         return any(re.search(pattern, content, re.MULTILINE) for pattern in code_patterns)

#     def wrap_code_content(self, content: str, language: str = "python") -> str:
#         """Wrap content in Markdown code block markers if it's code."""
#         if self.is_code_content(content):
#             return f"```{language}\n{content.rstrip()}\n```"
#         return content

#     async def process_message(self, message: Message) -> None:
#         print("ðŸš€ DEBUG: process_message å¼€å§‹æ‰§è¡Œ")
#         print(f"ðŸ” DEBUG: æ”¶åˆ°æ¶ˆæ¯: {message.body}")
        
#         self.send_message("ðŸ”§ è°ƒè¯•ï¼šJupyternautPersona.process_message æ­£åœ¨æ‰§è¡Œ...")
        
#         if not self.config_manager.lm_provider:
#             print("âŒ DEBUG: æ²¡æœ‰é…ç½®è¯­è¨€æ¨¡åž‹æä¾›è€…")
#             self.send_message(
#                 "No language model provider configured. Please set one in the Jupyter AI settings."
#             )
#             return

#         provider_name = self.config_manager.lm_provider.name
#         model_id = self.config_manager.lm_provider_params["model_id"]
#         api_base = self.config_manager.lm_provider_params.get("openai_api_base", "http://ai.gffunds.com.cn/llmapi/v1")
#         api_key = self.config_manager.lm_provider_params.get("openai_api_key", "")
#         print(f"ðŸ”§ DEBUG: æä¾›è€…: {provider_name}, æ¨¡åž‹: {model_id}, API ç«¯ç‚¹: {api_base}")
        
#         self.send_message(f"ðŸ”§ é…ç½®ç¡®è®¤ï¼šæä¾›è€…={provider_name}, æ¨¡åž‹={model_id}")

#         rag_context = self.get_rag_context(message.body)
#         print(f"[DEBUG] RAG ä¸Šä¸‹æ–‡é•¿åº¦: {len(rag_context)} å­—ç¬¦")

#         attach_context = self.process_attachments(message)
#         print(f"ðŸ“Ž DEBUG: é™„ä»¶ä¸Šä¸‹æ–‡é•¿åº¦: {len(attach_context) if attach_context else 0}")

#         context = rag_context + ("\n" + attach_context if attach_context else "")
#         print(f"[DEBUG] æœ€ç»ˆä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")

#         print("ðŸ”¨ DEBUG: å¼€å§‹æž„å»º runnable...")
#         try:
#             runnable = self.build_runnable()
#             print(f"âœ… DEBUG: runnable æž„å»ºå®Œæˆï¼Œç±»åž‹: {type(runnable)}")
#             self.send_message("ðŸ”§ runnable æž„å»ºæˆåŠŸ")
#         except Exception as e:
#             print(f"âŒ DEBUG: runnable æž„å»ºå¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"âŒ DEBUG: runnable é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             self.send_message(f"âŒ runnable æž„å»ºå¤±è´¥: {e}")
#             return
        
#         variables = JupyternautVariables(
#             input=message.body,
#             model_id=model_id,
#             provider_name=provider_name,
#             persona_name=self.name,
#             context=context,
#             history=[]  # åˆå§‹åŒ–ä¸ºç©º
#         )
        
#         history = []
#         try:
#             session_history = YChatHistory(ychat=self.ychat, k=2).messages
#             history = session_history if session_history else []
#             print(f"[DEBUG] åŽ†å²æ¶ˆæ¯æ•°é‡: {len(history)}, å†…å®¹: {history}")
#         except Exception as e:
#             print(f"[DEBUG] èŽ·å–åŽ†å²æ¶ˆæ¯å¤±è´¥: {type(e).__name__} - {e}")

#         variables_dict = variables.model_dump()
#         variables_dict["history"] = history
#         print(f"ðŸ“ DEBUG: å˜é‡å‡†å¤‡å®Œæˆï¼Œinputé•¿åº¦: {len(variables_dict.get('input', ''))}, contexté•¿åº¦: {len(variables_dict.get('context', ''))}, historyé•¿åº¦: {sum(len(str(msg)) for msg in history)}")

#         print("ðŸ” DEBUG: æ ¼å¼åŒ– prompt...")
#         try:
#             formatted_prompt = JUPYTERNAUT_PROMPT_TEMPLATE.format(**variables_dict)
#             print(f"[DEBUG] æ ¼å¼åŒ– prompt é•¿åº¦: {len(formatted_prompt)} å­—ç¬¦")
#         except Exception as e:
#             print(f"[DEBUG] æ ¼å¼åŒ– prompt å¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"[DEBUG] æ ¼å¼åŒ– prompt é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             self.send_message(f"âŒ prompt æ ¼å¼åŒ–å¤±è´¥: {e}")
#             return

#         print("ðŸ” DEBUG: æ£€æŸ¥ä¸Šä¸‹æ–‡é•¿åº¦...")
#         length_info = self.check_context_length(formatted_prompt, history, api_base, api_key, model_id)
#         print(f"[DEBUG] ä¸Šä¸‹æ–‡é•¿åº¦æ£€æŸ¥ç»“æžœ: {length_info}")
#         if length_info["is_exceeded"]:
#             self.send_message(f"âŒ ä¸Šä¸‹æ–‡é•¿åº¦è¶…è¿‡é™åˆ¶: æ€»è®¡ {length_info['total_tokens']} tokensï¼Œæœ€å¤§å…è®¸ {length_info['max_tokens']} tokens")
#             return

#         print("ðŸ”„ DEBUG: å¼€å§‹åˆ›å»º reply_stream...")
#         try:
#             reply_stream = runnable.astream(variables_dict)
#             print(f"âœ… DEBUG: reply_stream åˆ›å»ºæˆåŠŸï¼Œç±»åž‹: {type(reply_stream)}")
#             buffer = ""
#             code_block_buffer = ""
#             in_code_block = False
#             chunk_count = 0
#             async for chunk in reply_stream:
#                 print(f"[DEBUG] LangChain chunk[{chunk_count}]: {chunk}")
#                 if chunk:
#                     buffer += chunk
#                     if "```" in chunk:
#                         if in_code_block:
#                             code_block_buffer += chunk
#                             in_code_block = False
#                             formatted_content = self.wrap_code_content(code_block_buffer)
#                             self.send_message(formatted_content.strip())
#                             print(f"[DEBUG] å‘é€å®Œæ•´ä»£ç å—: {formatted_content.strip()}")
#                             code_block_buffer = ""
#                         else:
#                             in_code_block = True
#                             pre_code = buffer[:buffer.rindex("```")].strip()
#                             if pre_code:
#                                 self.send_message(pre_code)
#                                 print(f"[DEBUG] å‘é€ä»£ç å—å‰æ–‡æœ¬: {pre_code}")
#                             code_block_buffer = buffer[buffer.rindex("```"):]
#                             buffer = ""
#                     elif in_code_block:
#                         code_block_buffer += chunk
#                     else:
#                         if any(buffer.endswith(p) for p in [".", "!", "?", "\n"]):
#                             formatted_content = self.wrap_code_content(buffer)
#                             self.send_message(formatted_content.strip())
#                             print(f"[DEBUG] å‘é€å¥å­: {formatted_content.strip()}")
#                             buffer = ""
#                         elif len(buffer) > 200:
#                             formatted_content = self.wrap_code_content(buffer)
#                             self.send_message(formatted_content.strip())
#                             print(f"[DEBUG] å‘é€é•¿ç¼“å†²: {formatted_content.strip()}")
#                             buffer = ""
#                 chunk_count += 1
#             if code_block_buffer:
#                 formatted_content = self.wrap_code_content(code_block_buffer)
#                 self.send_message(formatted_content.strip())
#                 print(f"[DEBUG] å‘é€å‰©ä½™ä»£ç å—: {formatted_content.strip()}")
#             elif buffer:
#                 formatted_content = self.wrap_code_content(buffer)
#                 self.send_message(formatted_content.strip())
#                 print(f"[DEBUG] å‘é€å‰©ä½™ç¼“å†²: {formatted_content.strip()}")
#             print(f"[DEBUG] LangChain æ€»è®¡æŽ¥æ”¶ {chunk_count} ä¸ª chunk")
#             if chunk_count == 0:
#                 self.send_message("âŒ LangChain æœªæŽ¥æ”¶åˆ°ä»»ä½• chunkï¼Œå¯èƒ½æ˜¯è§£æžé—®é¢˜")
#         except Exception as e:
#             print(f"[DEBUG] reply_stream å¼‚å¸¸: {type(e).__name__} - {e}")
#             import traceback
#             print(f"[DEBUG] reply_stream é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             self.send_message(f"âŒ reply_stream å¼‚å¸¸: {e}")

#         print("ðŸ” DEBUG: ç›´æŽ¥ä½¿ç”¨ API æµå¼è¾“å‡ºï¼ˆä»…ç”¨äºŽå¯¹æ¯”ï¼‰...")
#         try:
#             headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
#             messages = [
#                 {"role": "system", "content": formatted_prompt},
#                 {"role": "user", "content": message.body}
#             ]
#             data = {
#                 "model": model_id,
#                 "messages": messages,
#                 "stream": True,
#                 "max_tokens": 4000,
#                 "temperature": 0.3
#             }
#             buffer = ""
#             code_block_buffer = ""
#             in_code_block = False
#             with requests.post(f"{api_base}/chat/completions", headers=headers, json=data, stream=True) as r:
#                 chunk_count = 0
#                 for line in r.iter_lines():
#                     if line:
#                         decoded_line = line.decode("utf-8")
#                         print(f"[DEBUG] API chunk[{chunk_count}]: {decoded_line}")
#                         if decoded_line.startswith("data: ") and decoded_line != "data: [DONE]":
#                             try:
#                                 chunk_data = json.loads(decoded_line[6:])
#                                 if "choices" in chunk_data and chunk_data["choices"]:
#                                     content = chunk_data["choices"][0].get("delta", {}).get("content", "")
#                                     if content:
#                                         buffer += content
#                                         if "```" in content:
#                                             if in_code_block:
#                                                 code_block_buffer += content
#                                                 in_code_block = False
#                                                 formatted_content = self.wrap_code_content(code_block_buffer)
#                                                 print(f"[DEBUG] API å‘é€å®Œæ•´ä»£ç å—: {formatted_content.strip()}")
#                                                 code_block_buffer = ""
#                                             else:
#                                                 in_code_block = True
#                                                 pre_code = buffer[:buffer.rindex("```")].strip()
#                                                 if pre_code:
#                                                     formatted_content = self.wrap_code_content(pre_code)
#                                                     print(f"[DEBUG] API å‘é€ä»£ç å—å‰æ–‡æœ¬: {formatted_content.strip()}")
#                                                 code_block_buffer = buffer[buffer.rindex("```"):]
#                                                 buffer = ""
#                                         elif in_code_block:
#                                             code_block_buffer += content
#                                         else:
#                                             if any(buffer.endswith(p) for p in [".", "!", "?", "\n"]):
#                                                 formatted_content = self.wrap_code_content(buffer)
#                                                 print(f"[DEBUG] API å‘é€å¥å­: {formatted_content.strip()}")
#                                                 buffer = ""
#                                             elif len(buffer) > 200:
#                                                 formatted_content = self.wrap_code_content(buffer)
#                                                 print(f"[DEBUG] API å‘é€é•¿ç¼“å†²: {formatted_content.strip()}")
#                                                 buffer = ""
#                                 chunk_count += 1
#                             except json.JSONDecodeError:
#                                 print(f"[DEBUG] JSON è§£æžå¤±è´¥: {decoded_line}")
#                 if code_block_buffer:
#                     formatted_content = self.wrap_code_content(code_block_buffer)
#                     print(f"[DEBUG] API å‘é€å‰©ä½™ä»£ç å—: {formatted_content.strip()}")
#                 if buffer:
#                     formatted_content = self.wrap_code_content(buffer)
#                     print(f"[DEBUG] API å‘é€å‰©ä½™ç¼“å†²: {formatted_content.strip()}")
#                 print(f"[DEBUG] API æ€»è®¡æŽ¥æ”¶ {chunk_count} ä¸ª chunk")
#         except Exception as e:
#             print(f"[DEBUG] ç›´æŽ¥ API æµå¼å¤„ç†å¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"[DEBUG] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             self.send_message(f"âŒ API æµå¼å¤„ç†å¤±è´¥: {e}")

#     def build_runnable(self) -> Any:
#         print("ðŸ”¨ DEBUG: build_runnable å¼€å§‹æ‰§è¡Œ")
        
#         print("ðŸ”§ DEBUG: åˆ›å»ºè¯­è¨€æ¨¡åž‹å®žä¾‹...")
#         async def stream_llm(input: Any) -> Iterator[str]:
#             print(f"[DEBUG] stream_llm è°ƒç”¨: input={str(input)[:50]}...")
#             model_id = self.config_manager.lm_provider_params.get("model_id", "gpt-4o")
#             api_base = self.config_manager.lm_provider_params.get("openai_api_base", "http://ai.gffunds.com.cn/llmapi/v1")
#             api_key = self.config_manager.lm_provider_params.get("openai_api_key", "")
#             prompt = str(input)
#             try:
#                 headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
#                 data = {
#                     "model": model_id,
#                     "messages": [{"role": "user", "content": prompt}],
#                     "stream": True,
#                     "max_tokens": 4000,
#                     "temperature": 0.3
#                 }
#                 print(f"[DEBUG] å‘é€ API è¯·æ±‚: {json.dumps(data, ensure_ascii=False)[:100]}...")
#                 with requests.post(
#                     f"{api_base}/chat/completions",
#                     headers=headers,
#                     json=data,
#                     stream=True
#                 ) as response:
#                     chunk_count = 0
#                     buffer = ""
#                     code_block_buffer = ""
#                     in_code_block = False
#                     for line in response.iter_lines():
#                         if line:
#                             decoded_line = line.decode("utf-8")
#                             print(f"[DEBUG] Raw chunk[{chunk_count}]: {decoded_line}")
#                             if decoded_line.startswith("data: ") and decoded_line != "data: [DONE]":
#                                 try:
#                                     chunk_data = json.loads(decoded_line[6:])
#                                     print(f"[DEBUG] Parsed chunk[{chunk_count}]: {chunk_data}")
#                                     if "choices" in chunk_data and chunk_data["choices"]:
#                                         content = chunk_data["choices"][0].get("delta", {}).get("content", "")
#                                         if content:
#                                             buffer += content
#                                             if "```" in content:
#                                                 if in_code_block:
#                                                     code_block_buffer += content
#                                                     in_code_block = False
#                                                     formatted_content = self.wrap_code_content(code_block_buffer)
#                                                     yield formatted_content
#                                                     print(f"[DEBUG] äº§å‡ºå®Œæ•´ä»£ç å—: {formatted_content}")
#                                                     code_block_buffer = ""
#                                                 else:
#                                                     in_code_block = True
#                                                     pre_code = buffer[:buffer.rindex("```")].strip()
#                                                     if pre_code:
#                                                         formatted_content = self.wrap_code_content(pre_code)
#                                                         yield formatted_content
#                                                         print(f"[DEBUG] äº§å‡ºä»£ç å—å‰æ–‡æœ¬: {formatted_content}")
#                                                     code_block_buffer = buffer[buffer.rindex("```"):]
#                                                     buffer = ""
#                                             elif in_code_block:
#                                                 code_block_buffer += content
#                                             else:
#                                                 if any(buffer.endswith(p) for p in [".", "!", "?", "\n"]):
#                                                     formatted_content = self.wrap_code_content(buffer)
#                                                     yield formatted_content
#                                                     print(f"[DEBUG] äº§å‡ºå¥å­: {formatted_content}")
#                                                     buffer = ""
#                                                 elif len(buffer) > 200:
#                                                     formatted_content = self.wrap_code_content(buffer)
#                                                     yield formatted_content
#                                                     print(f"[DEBUG] äº§å‡ºé•¿ç¼“å†²: {formatted_content}")
#                                                     buffer = ""
#                                         elif chunk_data["choices"][0].get("finish_reason"):
#                                             yield ""
#                                     else:
#                                         print(f"[DEBUG] è·³è¿‡éžç”Ÿæˆ chunk: {chunk_data}")
#                                     chunk_count += 1
#                                 except json.JSONDecodeError:
#                                     print(f"[DEBUG] JSON è§£æžå¤±è´¥: {decoded_line}")
#                     if code_block_buffer:
#                         formatted_content = self.wrap_code_content(code_block_buffer)
#                         yield formatted_content
#                         print(f"[DEBUG] äº§å‡ºå‰©ä½™ä»£ç å—: {formatted_content}")
#                     if buffer:
#                         formatted_content = self.wrap_code_content(buffer)
#                         yield formatted_content
#                         print(f"[DEBUG] äº§å‡ºå‰©ä½™ç¼“å†²: {formatted_content}")
#                     print(f"[DEBUG] stream_llm æ€»è®¡æŽ¥æ”¶ {chunk_count} ä¸ª chunk")
#             except Exception as e:
#                 print(f"[DEBUG] stream_llm å¼‚å¸¸: {type(e).__name__} - {e}")
#                 import traceback
#                 print(f"[DEBUG] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#                 raise

#         try:
#             llm = RunnableLambda(stream_llm)
#             print(f"âœ… DEBUG: è¯­è¨€æ¨¡åž‹åˆ›å»ºæˆåŠŸï¼Œç±»åž‹: {type(llm)}")
#         except Exception as e:
#             print(f"âŒ DEBUG: è¯­è¨€æ¨¡åž‹åˆ›å»ºå¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             raise
        
#         print("ðŸ”§ DEBUG: æž„å»ºåŸºç¡€é“¾...")
#         try:
#             runnable = JUPYTERNAUT_PROMPT_TEMPLATE | llm | CustomStrOutputParser()
#             print(f"âœ… DEBUG: åŸºç¡€é“¾æž„å»ºæˆåŠŸï¼Œç±»åž‹: {type(runnable)}")
#         except Exception as e:
#             print(f"âŒ DEBUG: åŸºç¡€é“¾æž„å»ºå¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             raise

#         print("ðŸ”§ DEBUG: æ·»åŠ æ¶ˆæ¯åŽ†å²æ”¯æŒ...")
#         try:
#             history_obj = YChatHistory(ychat=self.ychat, k=2)
#             try:
#                 history_messages = history_obj.messages
#                 print(f"[DEBUG] åŽ†å²æ¶ˆæ¯: {history_messages}")
#             except Exception as e:
#                 print(f"[DEBUG] èŽ·å– YChatHistory æ¶ˆæ¯å¤±è´¥: {type(e).__name__} - {e}")
            
#             runnable = RunnableWithMessageHistory(
#                 runnable=runnable,
#                 get_session_history=lambda: history_obj,
#                 input_messages_key="input",
#                 history_messages_key="history",
#             )
#             print(f"âœ… DEBUG: æ¶ˆæ¯åŽ†å²æ”¯æŒæ·»åŠ æˆåŠŸï¼Œç±»åž‹: {type(runnable)}")
#         except Exception as e:
#             print(f"âŒ DEBUG: æ¶ˆæ¯åŽ†å²æ”¯æŒæ·»åŠ å¤±è´¥: {type(e).__name__} - {e}")
#             import traceback
#             print(f"âŒ DEBUG: é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
#             raise

#         print("âœ… DEBUG: build_runnable å®Œæˆ")
#         return runnable