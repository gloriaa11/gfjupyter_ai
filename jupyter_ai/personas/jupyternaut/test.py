import asyncio
from unittest.mock import AsyncMock, MagicMock
from jupyterlab_chat.models import Message
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory

# å‡è®¾è¿™äº›æ˜¯æ‚¨æä¾›çš„ JupyternautPersona ç±»çš„ä¾èµ–
from jupyternaut import JupyternautPersona
from prompt_template import  JUPYTERNAUT_PROMPT_TEMPLATE, JupyternautVariables

async def test_jupyternaut_persona():
    print("ğŸ”§ å¼€å§‹æµ‹è¯• JupyternautPersona...")

    # åˆ›å»º mock çš„ config_manager
    config_manager = MagicMock()
    config_manager.lm_provider = MagicMock(name="MockProvider")
    config_manager.lm_provider_params = {"model_id": "mock-model"}
    config_manager.lm_provider.name = "MockProvider"

    # åˆ›å»º mock çš„è¯­è¨€æ¨¡å‹
    mock_llm = AsyncMock()
    mock_llm.invoke = AsyncMock(return_value="This is a mock response from the language model.")
    mock_llm.astream = AsyncMock(return_value=AsyncMock(__aiter__=lambda: mock_stream()))

    # æ¨¡æ‹Ÿ RAGSystem
    mock_rag_system = MagicMock()
    mock_rag_system.search.return_value = [
        {"title": "Doc1", "content": "Jupyter AI is an AI-powered extension for JupyterLab.", "similarity_score": 0.95},
        {"title": "Doc2", "content": "It provides AI-driven features for coding.", "similarity_score": 0.90}
    ]

    # æ¨¡æ‹Ÿ YChatHistory
    mock_ychat_history = MagicMock()
    mock_ychat_history.get_messages.return_value = []

    # æ¨¡æ‹Ÿ stream_message æ–¹æ³•
    async def mock_stream_message(reply_stream):
        async for chunk in reply_stream:
            print(f"ğŸ“¤ æ”¶åˆ°æµå¼è¾“å‡º: {chunk}")

    # åˆ›å»º JupyternautPersona å®ä¾‹
    persona = JupyternautPersona()
    persona.config_manager = config_manager
    persona.ychat = MagicMock()
    persona._rag_system = mock_rag_system
    persona.send_message = MagicMock()
    persona.stream_message = mock_stream_message
    persona.process_attachments = MagicMock(return_value="")

    # æ¨¡æ‹Ÿè¯­è¨€æ¨¡å‹æä¾›è€…çš„å®ä¾‹åŒ–
    config_manager.lm_provider = MagicMock(return_value=mock_llm)

    # æµ‹è¯•æ¶ˆæ¯
    test_message = Message(body="What is Jupyter AI?")

    print("ğŸš€ æµ‹è¯• process_message æ–¹æ³•...")
    await persona.process_message(test_message)

    # éªŒè¯ send_message è¢«è°ƒç”¨
    persona.send_message.assert_any_call("ğŸ”§ è°ƒè¯•ï¼šJupyternautPersona.process_message æ­£åœ¨æ‰§è¡Œ...")
    persona.send_message.assert_any_call("ğŸ”§ é…ç½®ç¡®è®¤ï¼šæä¾›è€…=MockProvider, æ¨¡å‹=mock-model")
    persona.send_message.assert_any_call("ğŸ”§ runnable æ„å»ºæˆåŠŸ")
    print("âœ… send_message è°ƒç”¨éªŒè¯é€šè¿‡")

    print("âœ… æµ‹è¯•å®Œæˆï¼")

# æ¨¡æ‹Ÿæµå¼è¾“å‡ºçš„å¼‚æ­¥è¿­ä»£å™¨
async def mock_stream():
    yield "This is "
    yield "a mock "
    yield "response from "
    yield "the language model."

# è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    asyncio.run(test_jupyternaut_persona())